{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExuV3ktSQYrH"
   },
   "source": [
    "<center><img src=\"https://github.com/hse-ds/iad-applied-ds/blob/master/2021/hw/hw1/img/logo_hse.png?raw=1\" width=\"1000\"></center>\n",
    "\n",
    "<h1><center>Applied data analysis tasks</center></h1>\n",
    "<h2><center>Homework 4: Recommendation systems</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef6180WvQbD-"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In this assignment, you will continue to work with the data from the workshop [Articles Sharing and Reading from CI&T Deskdrop](https://www.kaggle.com/gspmoreira/articles-sharing-reading-from-cit-deskdrop)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSV_mxD9TciM"
   },
   "source": [
    "# Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "M5mH3ZolSlcm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRQVuRvER0hd"
   },
   "source": [
    "We will upload the data and pre-process the data as in a seminar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gts3hsrASsiB",
    "outputId": "3f37bc4c-7157-4c8b-df74-ac92f09b0c09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.7.4.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: bleach in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (3.7)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (5.29.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (75.8.0)\n",
      "Requirement already satisfied: six>=1.10 in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: text-unidecode in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (2.3.0)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/lib/python3.12/site-packages (from kaggle) (0.5.1)\n",
      "Downloading kaggle-1.7.4.2-py3-none-any.whl (173 kB)\n",
      "Installing collected packages: kaggle\n",
      "\u001b[33m  WARNING: The script kaggle is installed in '/Users/nikitadvornov/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed kaggle-1.7.4.2\n"
     ]
    }
   ],
   "source": [
    "! pip install --user kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "XPYc-LuXTS68",
    "outputId": "61d4e62d-fa21-4bc8-fda6-d77337240266"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))\n",
    "  \n",
    "# Then move kaggle.json into the folder where the API expects to find it.\n",
    "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8E837g9kQTbb",
    "outputId": "bf5eb3d7-03da-409a-b430-8501261ab0e8"
   },
   "outputs": [],
   "source": [
    "!kaggle datasets download -d gspmoreira/articles-sharing-reading-from-cit-deskdrop\n",
    "!unzip articles-sharing-reading-from-cit-deskdrop.zip -d articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "id": "hdM1xSchR9jt",
    "outputId": "a99de1b0-d506-4e1c-fc89-8bb72ba2ce4d"
   },
   "outputs": [],
   "source": [
    "articles_df = pd.read_csv(\"articles/shared_articles.csv\")\n",
    "articles_df = articles_df[articles_df[\"eventType\"] == \"CONTENT SHARED\"]\n",
    "articles_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "KK9wMAkvSjbk",
    "outputId": "84562773-4d8f-487f-a69b-c45aa095e8f7"
   },
   "outputs": [],
   "source": [
    "interactions_df = pd.read_csv(\"articles/users_interactions.csv\")\n",
    "interactions_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5nQScdSTTzNG"
   },
   "outputs": [],
   "source": [
    "interactions_df.personId = interactions_df.personId.astype(str)\n",
    "interactions_df.contentId = interactions_df.contentId.astype(str)\n",
    "articles_df.contentId = articles_df.contentId.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eu6R9rDQT2P4"
   },
   "outputs": [],
   "source": [
    "# зададим словарь определяющий силу взаимодействия\n",
    "event_type_strength = {\n",
    "   \"VIEW\": 1.0,\n",
    "   \"LIKE\": 2.0, \n",
    "   \"BOOKMARK\": 2.5, \n",
    "   \"FOLLOW\": 3.0,\n",
    "   \"COMMENT CREATED\": 4.0,  \n",
    "}\n",
    "\n",
    "interactions_df[\"eventStrength\"] = interactions_df.eventType.apply(lambda x: event_type_strength[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "id": "iiuqgFvhVMbT",
    "outputId": "ce30699f-0bd6-4fcb-eb2c-75f4b9bb6854"
   },
   "outputs": [],
   "source": [
    "interactions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATO5PRRwUkQ0"
   },
   "source": [
    "We leave only those users who have interacted with more than five articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HRgZZPZUaDx_",
    "outputId": "e30dab3f-f77f-4ca6-8c26-29fafb746b1c"
   },
   "outputs": [],
   "source": [
    "interactions_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d-0HoboYUBm5",
    "outputId": "54eb9162-409c-4edf-a2a3-d69d45374ff3"
   },
   "outputs": [],
   "source": [
    "users_interactions_count_df = (\n",
    "    interactions_df\n",
    "    .groupby([\"personId\", \"contentId\"])\n",
    "    .first()\n",
    "    .reset_index()\n",
    "    .groupby(\"personId\").size())\n",
    "print(\"# users:\", len(users_interactions_count_df))\n",
    "\n",
    "users_with_enough_interactions_df = \\\n",
    "    users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[[\"personId\"]]\n",
    "print(\"# users with at least 5 interactions:\",len(users_with_enough_interactions_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQagI3DHUuX5"
   },
   "source": [
    "We leave only those interactions that relate to filtered users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34rrdGdpUFgk"
   },
   "outputs": [],
   "source": [
    "interactions_from_selected_users_df = interactions_df.loc[np.in1d(interactions_df.personId,\n",
    "            users_with_enough_interactions_df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hd3VS_BgU9HN",
    "outputId": "38774200-d43e-4e10-9823-960737d119a8"
   },
   "outputs": [],
   "source": [
    "print(f\"# interactions before: {interactions_df.shape}\")\n",
    "print(f\"# interactions after: {interactions_from_selected_users_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYpRiFkQVR6B"
   },
   "source": [
    "We combine all user interactions for each article and smooth the result by taking the logarithm from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "mtPtAehKVEUu",
    "outputId": "167d312e-73b1-4b93-c568-080cf7785797"
   },
   "outputs": [],
   "source": [
    "def smooth_user_preference(x):\n",
    "    return math.log(1+x, 2)\n",
    "    \n",
    "interactions_full_df = (\n",
    "    interactions_from_selected_users_df\n",
    "    .groupby([\"personId\", \"contentId\"]).eventStrength.sum()\n",
    "    .apply(smooth_user_preference)\n",
    "    .reset_index().set_index([\"personId\", \"contentId\"])\n",
    ")\n",
    "interactions_full_df[\"last_timestamp\"] = (\n",
    "    interactions_from_selected_users_df\n",
    "    .groupby([\"personId\", \"contentId\"])[\"timestamp\"].last()\n",
    ")\n",
    "        \n",
    "interactions_full_df = interactions_full_df.reset_index()\n",
    "interactions_full_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODJYMtnNWM5w"
   },
   "source": [
    "Let's split the sample into training and time control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "3F2CfAwoVrfo",
    "outputId": "7974f4f0-0f7c-472f-95ea-e05cccce18f2"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "split_ts = 1475519530\n",
    "interactions_train_df = interactions_full_df.loc[interactions_full_df.last_timestamp < split_ts].copy()\n",
    "interactions_test_df = interactions_full_df.loc[interactions_full_df.last_timestamp >= split_ts].copy()\n",
    "\n",
    "print(f\"# interactions on Train set: {len(interactions_train_df)}\")\n",
    "print(f\"# interactions on Test set: {len(interactions_test_df)}\")\n",
    "\n",
    "interactions_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5G3FTYOXLVg"
   },
   "source": [
    "For the convenience of calculating the quality, we will write the data in a format where the row corresponds to the user, and the columns will be true labels and predictions in the form of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "RT-_toqfXOa2",
    "outputId": "262c510c-6b3b-4839-f74a-b95fa95a7c2e"
   },
   "outputs": [],
   "source": [
    "interactions = (\n",
    "    interactions_train_df\n",
    "    .groupby(\"personId\")[\"contentId\"].agg(lambda x: list(x))\n",
    "    .reset_index()\n",
    "    .rename(columns={\"contentId\": \"true_train\"})\n",
    "    .set_index(\"personId\")\n",
    ")\n",
    "\n",
    "interactions[\"true_test\"] = (\n",
    "    interactions_test_df\n",
    "    .groupby(\"personId\")[\"contentId\"].agg(lambda x: list(x))\n",
    ")\n",
    "\n",
    "# заполнение пропусков пустыми списками\n",
    "interactions.loc[pd.isnull(interactions.true_test), \"true_test\"] = [\n",
    "    \"\" for x in range(len(interactions.loc[pd.isnull(interactions.true_test), \"true_test\"]))]\n",
    "\n",
    "interactions.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-UWDyWKsamSa"
   },
   "source": [
    "# LightFM library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-iXjvdZa25Z"
   },
   "source": [
    "For recommendation, you will use the [LightFM](https://making.lyst.com/lightfm/docs/home.html) library, which implements popular algorithms. For evaluating the quality of the recommendation, as in the seminar, we will use the *precision@10* metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bXhGyeqCvVCp",
    "outputId": "f7105638-e10c-4291-e788-ed95372b19a8"
   },
   "outputs": [],
   "source": [
    "!pip install lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qtyn38PZXPLf"
   },
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0CjyGqulcZTf"
   },
   "source": [
    "## Task 1 (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Sof6V5Dd4h9"
   },
   "source": [
    "Models in LightFM work with sparse matrices. Create sparse matrices `data_train` and `data_test` (with dimensions equal to the number of users by the number of items), where the value at the intersection of a user row and an item column represents the strength of their interaction if there was one, and zero if there was no interaction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1cLZ5ga4eIdg"
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "data_train = pd.pivot_table(\n",
    "    interactions_train_df,\n",
    "    values='eventStrength',\n",
    "    index='personId',\n",
    "    columns='contentId').fillna(0)\n",
    "data_test = pd.pivot_table(\n",
    "    interactions_test_df,\n",
    "    values='eventStrength',\n",
    "    index='personId',\n",
    "    columns='contentId').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AiNGVzTveRXE"
   },
   "source": [
    "## Task 2 (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPfVK3STeryM"
   },
   "source": [
    "Train model LightFM with `loss=\"warp\"` and count *precision@10* on the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hj-Rl8XJt6G9"
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "data_train = pd.pivot_table(\n",
    "    interactions_full_df,\n",
    "    values='eventStrength',\n",
    "    index='personId',\n",
    "    columns='contentId').fillna(0)\n",
    "data_test = pd.pivot_table(\n",
    "    interactions_test_df,\n",
    "    values='eventStrength',\n",
    "    index='personId',\n",
    "    columns='contentId').fillna(0)\n",
    "print(data_train.index.shape)\n",
    "print(data_train.columns.values.shape)\n",
    "print(data_test.index.shape)\n",
    "print(data_test.columns.values.shape)\n",
    "users_needed = np.arange(1140)[np.in1d(data_train.index, data_test.index)] # ids of users from data_train met in data_test\n",
    "items_needed = np.arange(2984)[np.in1d(data_train.columns.values, data_test.columns.values)] # ids of items from data_train met in data_test\n",
    "user_ids = np.repeat(users_needed, items_needed.shape)\n",
    "item_ids = np.array([])\n",
    "for i in range(users_needed.shape[0]):\n",
    "  item_ids = np.append(item_ids, items_needed) # np.arrays of indeces (according to interactions matrix) of test users and test items \n",
    "# Ваш код здесь\n",
    "model = LightFM(loss='warp')\n",
    "model.fit(csr_matrix(data_train.to_numpy()))\n",
    "predictions = model.predict(user_ids, item_ids)\n",
    "print(precision_at_k(model, csr_matrix(data_train), k=10).mean())\n",
    "print(precision_at_k(model, csr_matrix(data_test), k=10).mean())\n",
    "print(precision_at_k(model, csr_matrix(data_test), csr_matrix(data_train), k=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EJba9O52O4JC"
   },
   "outputs": [],
   "source": [
    "#Создадим маппинг для пользователей и фильмов\n",
    "user_id_mapping = {id:i for i, id in enumerate(interactions_full_df['personId'].unique())}\n",
    "item_id_mapping = {id:i for i, id in enumerate(interactions_full_df['contentId'].unique())}\n",
    "\n",
    "Применим его к обучающему и тренировочному набору\n",
    "train_user_data = interactions_train_df['personId'].map(user_id_mapping)\n",
    "train_item_data = interactions_train_df['contentId'].map(item_id_mapping)\n",
    "\n",
    "test_user_data = interactions_test_df['personId'].map(user_id_mapping)\n",
    "test_item_data = interactions_test_df['contentId'].map(item_id_mapping)\n",
    "\n",
    "#Создадим разреженную матрицу рейтинга\n",
    "shape = (len(user_id_mapping), len(item_id_mapping))\n",
    "train_matrix = coo_matrix((interactions_train_df['eventStrength'].values, (train_user_data.astype(int), train_item_data.astype(int))), shape=shape)\n",
    "test_matrix = coo_matrix((interactions_test_df['eventStrength'].values, (test_user_data.astype(int), test_item_data.astype(int))), shape=shape)\n",
    "\n",
    "#Создадим модель LightFM и обучим ем\n",
    "model = LightFM(loss='warp')\n",
    "%timeit model.fit(train_matrix, epochs=30, num_threads=2)\n",
    "# predictions = model.predict(test_user_data.values, test_item_data.values)\n",
    "\n",
    "k = 10\n",
    "print('Train precision at k={}:\\t{:.4f}'.format(k, precision_at_k(model, train_matrix, k=k).mean()))\n",
    "print('Test precision at k={}:\\t\\t{:.4f}'.format(k, precision_at_k(model, test_matrix, k=k).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VcLRUnnqXpo0"
   },
   "outputs": [],
   "source": [
    "from lightfm.data import Dataset\n",
    "\n",
    "dataset = Dataset()\n",
    "dataset.fit((int(x[1].personId) for x in interactions_full_df.iterrows()),\n",
    "            (int(x[1].contentId) for x in interactions_full_df.iterrows()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mH1saGgaUDjd",
    "outputId": "62d7b353-253a-4f26-ebbc-071222620823"
   },
   "outputs": [],
   "source": [
    "num_users, num_items = dataset.interactions_shape()\n",
    "print('Num users: {}, num_items {}.'.format(num_users, num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v4JjsEv-S5rM",
    "outputId": "01d00c9c-05de-445b-cec5-0d6a87eadf4d"
   },
   "outputs": [],
   "source": [
    "(interactions_train, weights) = dataset.build_interactions((int(x[1].personId), int(x[1].contentId))\n",
    "                                                      for x in interactions_train_df.iterrows())\n",
    "print(repr(interactions_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-fNlLXhPd2S4",
    "outputId": "bece194c-1663-4856-eea0-f6e9a4656458"
   },
   "outputs": [],
   "source": [
    "(interactions_test, weights) = dataset.build_interactions((int(x[1].personId), int(x[1].contentId))\n",
    "                                                      for x in interactions_test_df.iterrows())\n",
    "print(repr(interactions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JlEGzrfLZlpu",
    "outputId": "ff35d46d-d192-42ff-b369-aba716c46f2e"
   },
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "\n",
    "model = LightFM(loss='warp')\n",
    "model.fit(interactions_train) #item_features=item_features)\n",
    "# predictions = model.predict(user_ids, item_ids) для чего метод predict?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TBX1ABo8ZqhT",
    "outputId": "24a7df30-ff06-43ac-b85b-d8edb3fec6bd"
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "print('Train precision at k={}:\\t{:.4f}'.format(k, precision_at_k(model, interactions_train, k=k).mean()))\n",
    "print('Test precision at k={}:\\t\\t{:.4f}'.format(k, precision_at_k(model, interactions_test, k=k).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "oJJDdUmdZcLC",
    "outputId": "0a449a9a-e3dc-4784-f41b-0bbf8fd5448b"
   },
   "outputs": [],
   "source": [
    "item_features = dataset.build_item_features(((x['ISBN'], [x['Book-Author']])\n",
    "                                              for x in get_book_features()))\n",
    "print(repr(item_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZDsG1iAfdrl"
   },
   "source": [
    "## Task 3 (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F93chvtbgA9N"
   },
   "source": [
    "When calling the `fit` method, LightFM allows passing `item_features` which represent the feature descriptions of the items. Let's make use of this. We will obtain the feature descriptions from the article text in the form of [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) (you can use `TfidfVectorizer` from scikit-learn). Create a matrix `feat` with dimensions equal to the number of articles by the size of the feature description and train LightFM with `loss=\"warp\"`, then calculate precision@10 on the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c3VCFH27Wdpx"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5SvUi_Fofgf5"
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "feat = tfidf_vec.fit_transform(articles_df['text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZrAMaI4ALVWm"
   },
   "outputs": [],
   "source": [
    "feat = pd.DataFrame(feat, columns=np.arange(72615))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wJKZCNYSLsDl"
   },
   "outputs": [],
   "source": [
    "articles_concatted = articles_df.reset_index(drop=True).join(feat, how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CwmvLuRMNk2K"
   },
   "outputs": [],
   "source": [
    "articles_concatted.drop(['timestamp',\t'eventType', 'authorPersonId', 'authorSessionId',\t'authorUserAgent',\t'authorRegion',\n",
    "                         'authorCountry',\t'contentType',\t'url',\t'title',\t'text',\t'lang'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "GWMtsD-wSOKH",
    "outputId": "1157f9af-d1f9-46a8-ba62-b6cef1bd0a45"
   },
   "outputs": [],
   "source": [
    "articles_concatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0C00TaCzKHNy"
   },
   "outputs": [],
   "source": [
    "pd.merge(interactions_full_df, articles_concatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p4StN34-i-0Y"
   },
   "outputs": [],
   "source": [
    "dataset.fit(users=(int(x[1].personId) for x in interactions_full_df.iterrows()),\n",
    "            items=(int(x[1].contentId) for x in interactions_full_df.iterrows()),\n",
    "            item_features=(x[1].tf_idf for x in interactions_full_df.iterrows()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMzD8BjeIUP1"
   },
   "outputs": [],
   "source": [
    "num_users, num_items = dataset.interactions_shape()\n",
    "print('Num users: {}, num_items {}.'.format(num_users, num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ihtGb7XqYETK"
   },
   "outputs": [],
   "source": [
    "model = LightFM(loss='warp')\n",
    "%timeit model.fit(train_matrix, item_features=feat, epochs=30, num_threads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MCrspud6YApy"
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "print('Train precision at k={}:\\t{:.4f}'.format(k, precision_at_k(model, train_matrix, k=k).mean()))\n",
    "print('Test precision at k={}:\\t\\t{:.4f}'.format(k, precision_at_k(model, test_matrix, k=k).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Lwuex6PpsFw"
   },
   "source": [
    "## Task 4 (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5aZcHjSzp2cZ"
   },
   "source": [
    "In task 3, we used the raw text of the articles. In this task, you must first pre-process the text (reduce it to lowercase, remove stop words, restore words to normal form, etc.), then train the model and evaluate the quality on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_mOl8gceabnL"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J3-lvO5fgJyO"
   },
   "outputs": [],
   "source": [
    "articles_df['lang'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lXd-VLhugXlw"
   },
   "outputs": [],
   "source": [
    "print(stopwords.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J2m89g5pa1vd"
   },
   "outputs": [],
   "source": [
    "stop_words_lang = stopwords.words('english') + stopwords.words('portuguese') + stopwords.words('spanish') # no latin and japanese in stopwords module\n",
    "punctuation = []\n",
    "for char in string.punctuation:\n",
    "    punctuation.append(char)\n",
    "stop_words = punctuation + stop_words_lang\n",
    "\n",
    "def process_text(text):\n",
    "    return [word for word in word_tokenize(text.lower()) if word not in stop_words]\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "def to_lemmatize(sentence):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in sentence])\n",
    "\n",
    "articles_df['text_processed'] = articles_df['text'].apply(process_text).apply(to_lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "IAD, HW4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
